{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<http.client.HTTPResponse at 0x1d7498df1c0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://finance.naver.com/sise/\" \n",
    "page = urlopen(url) \n",
    "page "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b\"<script language='javascript'>\\n\",\n",
       " b'\\n',\n",
       " b'function main_tab(tab_title, pst, tab_cnt)\\n',\n",
       " b'{\\n',\n",
       " b'\\tfor(var i=0 ; i<tab_cnt ; i++)\\n',\n",
       " b'\\t{\\n',\n",
       " b'\\t\\tif (i == pst)\\n',\n",
       " b\"\\t\\t\\tdocument.getElementById(tab_title+'_title_tab_'+i).style.display = '';\\n\",\n",
       " b'\\t\\telse\\n',\n",
       " b\"\\t\\t\\tdocument.getElementById(tab_title+'_title_tab_'+i).style.display = 'none';\\n\",\n",
       " b'\\n',\n",
       " b'\\n',\n",
       " b'\\t\\tif (i == pst)\\n',\n",
       " b\"\\t\\t\\tdocument.getElementById(tab_title+'_tab_'+i).style.display = '';\\n\",\n",
       " b'\\t\\telse\\n',\n",
       " b\"\\t\\t\\tdocument.getElementById(tab_title+'_tab_'+i).style.display = 'none';\\n\",\n",
       " b'\\n',\n",
       " b'\\t}\\n',\n",
       " b'}\\n',\n",
       " b'\\n']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listpage = list(page) \n",
    "listpage[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "page = '''\n",
    "<html>\n",
    "<title>나의 홈페이지</title>\n",
    "<body>\n",
    "<div>\n",
    "<a href=\"https://www.naver.com/\">naver</a>\n",
    "<a href=\"https://www.google.com\">google</a>\n",
    "<img height=\"300\" src=\"dog_01.jpg\" width=\"500\"/>\n",
    "<p> 내가 가장 좋아하는 동물은 강아지입니다.</p>\n",
    "<p> 나는 그리고 네이버 홈페이지에 자주 갑니다.</p>\n",
    "<p class=\"p3\"> 강아지 사진과 네이버 링크 </p>\n",
    "<p id=\"p4\"> 간단한 나의 홈페이지를 만들다.</p>\n",
    "<p class=\"p3\"> 강아지 사진과 네이버 링크222 </p>\n",
    "</div>\n",
    "</body>\n",
    "</html>\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<html>\n",
       "<head><title>나의 홈페이지</title>\n",
       "</head><body>\n",
       "<div>\n",
       "<a href=\"https://www.naver.com/\">naver</a>\n",
       "<a href=\"https://www.google.com\">google</a>\n",
       "<img height=\"300\" src=\"dog_01.jpg\" width=\"500\"/>\n",
       "<p> 내가 가장 좋아하는 동물은 강아지입니다.</p>\n",
       "<p> 나는 그리고 네이버 홈페이지에 자주 갑니다.</p>\n",
       "<p class=\"p3\"> 강아지 사진과 네이버 링크 </p>\n",
       "<p id=\"p4\"> 간단한 나의 홈페이지를 만들다.</p>\n",
       "<p class=\"p3\"> 강아지 사진과 네이버 링크222 </p>\n",
       "</div>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup = BeautifulSoup(page, 'lxml') #lxml, parser, html5lib\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "제목 :  <title>나의 홈페이지</title>\n",
      "첫번째 a 태그 요소 :  <a href=\"https://www.naver.com/\">naver</a>\n",
      "첫번째 p 태그 요소 :  <p> 내가 가장 좋아하는 동물은 강아지입니다.</p>\n"
     ]
    }
   ],
   "source": [
    "# 요소 가져오기\n",
    "print(\"제목 : \", soup.title)\n",
    "print(\"첫번째 a 태그 요소 : \", soup.a)\n",
    "print(\"첫번째 p 태그 요소 : \", soup.p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<html>\n",
       "<head><title>나의 홈페이지</title>\n",
       "</head><body>\n",
       "<div>\n",
       "<a href=\"https://www.naver.com/\">naver</a>\n",
       "<a href=\"https://www.google.com\">google</a>\n",
       "<img height=\"300\" src=\"dog_01.jpg\" width=\"500\"/>\n",
       "<p> 내가 가장 좋아하는 동물은 강아지입니다.</p>\n",
       "<p> 나는 그리고 네이버 홈페이지에 자주 갑니다.</p>\n",
       "<p class=\"p3\"> 강아지 사진과 네이버 링크 </p>\n",
       "<p id=\"p4\"> 간단한 나의 홈페이지를 만들다.</p>\n",
       "<p class=\"p3\"> 강아지 사진과 네이버 링크222 </p>\n",
       "</div>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a href=\"https://www.naver.com/\">naver</a>,\n",
       " <a href=\"https://www.google.com\">google</a>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p> 내가 가장 좋아하는 동물은 강아지입니다.</p>,\n",
       " <p> 나는 그리고 네이버 홈페이지에 자주 갑니다.</p>,\n",
       " <p class=\"p3\"> 강아지 사진과 네이버 링크 </p>,\n",
       " <p id=\"p4\"> 간단한 나의 홈페이지를 만들다.</p>,\n",
       " <p class=\"p3\"> 강아지 사진과 네이버 링크222 </p>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(\"p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(' 간단한 나의 홈페이지를 만들다.', bs4.element.Tag)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a= soup.find(\"p\", id=\"p4\")\n",
    "a.text, type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.naver.com/\n",
      "https://www.google.com\n"
     ]
    }
   ],
   "source": [
    "for url in soup.find_all(\"a\"):\n",
    "    print(url['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'p4'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>나의 웹 페이지</title>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://pythonstart.github.io/web/\"\n",
    "\n",
    "page = urlopen(url)\n",
    "soup =BeautifulSoup(page, 'html.parser')\n",
    "soup.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<html>\n",
       "<head>\n",
       "<title>나의 웹 페이지</title>\n",
       "</head>\n",
       "<body>\n",
       "<h1> my web page </h1>\n",
       "<ul>\n",
       "<a href=\"./01.html\" name=\"link_get\" target=\"_blank\"> 01. 제목 가져오기(title) </a> <br/>\n",
       "<a href=\"./02.html\" name=\"text_get\" target=\"_blank\"> 02. 텍스트 가져오기(p) </a> <br/>\n",
       "<a href=\"./03.html\" name=\"link_get\" target=\"_blank\"> 03. 링크 가져오기(a) </a> <br/>\n",
       "<a href=\"https://pythonstart.github.io/web/04.html\" target=\"_blank\"> 04. 이미지 정보 가져오기(img) </a> <br/>\n",
       "<a href=\"./05.html\" target=\"_blank\"> 05. 리스트 정보 가져오기(ul,ol) </a> <br/>\n",
       "<a href=\"./06.html\" target=\"_blank\"> 06. id를 활용한 정보 획득 </a> <br/>\n",
       "<a href=\"./07.html\" target=\"_blank\"> 07. class를 활용한 정보 획득 </a> <br/>\n",
       "<a href=\"./08.html\" target=\"_blank\"> 08. 하나의 이미지 다운로드 </a> <br/>\n",
       "<a href=\"https://pythonstart.github.io/web/09.html\" target=\"_blank\"> 09. 여러개의 이미지 다운로드 </a> <br/>\n",
       "<a href=\"./10.html\" id=\"rank\" target=\"_blank\"> 10. 랭킹 정보 가져오기(웹 크롤링) </a> <br/>\n",
       "</ul>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a href=\"./10.html\" id=\"rank\" target=\"_blank\"> 10. 랭킹 정보 가져오기(웹 크롤링) </a>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('a', id='rank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h1> my web page </h1>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.h1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./01.html\n",
      "./02.html\n",
      "./03.html\n",
      "https://pythonstart.github.io/web/04.html\n",
      "./05.html\n",
      "./06.html\n",
      "./07.html\n",
      "./08.html\n",
      "https://pythonstart.github.io/web/09.html\n",
      "./10.html\n"
     ]
    }
   ],
   "source": [
    "a = soup.find_all('a')\n",
    "for i in a:\n",
    "    print(i['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_url = \"https://pythonstart.github.io/web/04.html\"\n",
    "\n",
    "img_page = urlopen(img_url)\n",
    "soup = BeautifulSoup(img_page, 'lxml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<html>\n",
       "<head>\n",
       "<title> 하나의 이미지 가져오기 </title>\n",
       "</head>\n",
       "<body>\n",
       "<div class=\"img01\">\n",
       "<p> 당신이 좋아할지도 모르는 이미지 </p>\n",
       "<div class=\"itemlike\" style=\"width: 322px; height: 214px; display: block;\"><img height=\"214px\" src=\"dog01.jpg\" width=\"322px\"/></div>\n",
       "<div class=\"itemlike\" style=\"width: 322px; height: 214px; display: block;\"><img height=\"214px\" src=\"dog02.jpg\" width=\"322px\"/></div>\n",
       "<a href=\"https://pixabay.com/ko/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=1785760\">Pixabay</a>로부터 입수된 \n",
       "<a href=\"https://pixabay.com/ko/users/kim_hester-3648659/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=1785760\">kim_hester</a>님의 이미지 입니다.\n",
       "</div>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<img height=\"214px\" src=\"dog01.jpg\" width=\"322px\"/>]\n",
      "dog01.jpg\n"
     ]
    }
   ],
   "source": [
    "img = soup.find('div', \"itemlike\").find_all('img')\n",
    "\n",
    "print(img)\n",
    "img_list = []\n",
    "for i in img:\n",
    "    a = i['src']\n",
    "    print(a)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'<html>\\n<head>\\n\\t<title>\\xeb\\x82\\x98\\xec\\x9d\\x98 \\xec\\x9b\\xb9 \\xed\\x8e\\x98\\xec\\x9d\\xb4\\xec\\xa7\\x80</title>\\n</head>\\n<body>\\n\\t<h1> my web page </h1>\\n\\t<ul>\\n\\t\\t<a href=\"./01.html\" name=\\'link_get\\' target=\"_blank\"> 01. \\xec\\xa0\\x9c\\xeb\\xaa\\xa9 \\xea\\xb0\\x80\\xec\\xa0\\xb8\\xec\\x98\\xa4\\xea\\xb8\\xb0(title) </a> <br>\\n\\t\\t<a href=\"./02.html\" name=\\'text_get\\' target=\"_blank\"> 02. \\xed\\x85\\x8d\\xec\\x8a\\xa4\\xed\\x8a\\xb8 \\xea\\xb0\\x80\\xec\\xa0\\xb8\\xec\\x98\\xa4\\xea\\xb8\\xb0(p) </a> <br>\\n\\t\\t<a href=\"./03.html\" name=\\'link_get\\' target=\"_blank\"> 03. \\xeb\\xa7\\x81\\xed\\x81\\xac \\xea\\xb0\\x80\\xec\\xa0\\xb8\\xec\\x98\\xa4\\xea\\xb8\\xb0(a) </a> <br>\\n\\t\\t<a href=\"https://ldjwj.github.io/webPage/04.html\" target=\"_blank\"> 04. \\xec\\x9d\\xb4\\xeb\\xaf\\xb8\\xec\\xa7\\x80 \\xec\\xa0\\x95\\xeb\\xb3\\xb4 \\xea\\xb0\\x80\\xec\\xa0\\xb8\\xec\\x98\\xa4\\xea\\xb8\\xb0(img) </a> <br>\\n\\t\\t<a href=\"./05.html\" target=\"_blank\"> 05. \\xeb\\xa6\\xac\\xec\\x8a\\xa4\\xed\\x8a\\xb8 \\xec\\xa0\\x95\\xeb\\xb3\\xb4 \\xea\\xb0\\x80\\xec\\xa0\\xb8\\xec\\x98\\xa4\\xea\\xb8\\xb0(ul,ol) </a> <br>\\n\\t\\t<a href=\"./06.html\" target=\"_blank\"> 06. id\\xeb\\xa5\\xbc \\xed\\x99\\x9c\\xec\\x9a\\xa9\\xed\\x95\\x9c \\xec\\xa0\\x95\\xeb\\xb3\\xb4 \\xed\\x9a\\x8d\\xeb\\x93\\x9d </a> <br>\\n\\t\\t<a href=\"./07.html\" target=\"_blank\"> 07. class\\xeb\\xa5\\xbc \\xed\\x99\\x9c\\xec\\x9a\\xa9\\xed\\x95\\x9c \\xec\\xa0\\x95\\xeb\\xb3\\xb4 \\xed\\x9a\\x8d\\xeb\\x93\\x9d </a> <br>\\n\\t\\t<a href=\"./08.html\" target=\"_blank\"> 08. \\xed\\x95\\x98\\xeb\\x82\\x98\\xec\\x9d\\x98 \\xec\\x9d\\xb4\\xeb\\xaf\\xb8\\xec\\xa7\\x80 \\xeb\\x8b\\xa4\\xec\\x9a\\xb4\\xeb\\xa1\\x9c\\xeb\\x93\\x9c </a> <br>\\n\\t\\t<a href=\"https://pythonstart.github.io/web/09.html\" target=\"_blank\"> 09. \\xec\\x97\\xac\\xeb\\x9f\\xac\\xea\\xb0\\x9c\\xec\\x9d\\x98 \\xec\\x9d\\xb4\\xeb\\xaf\\xb8\\xec\\xa7\\x80 \\xeb\\x8b\\xa4\\xec\\x9a\\xb4\\xeb\\xa1\\x9c\\xeb\\x93\\x9c </a> <br>\\n\\t\\t<a id=\"rank\" href=\"./10.html\" target=\"_blank\"> 10. \\xeb\\x9e\\xad\\xed\\x82\\xb9 \\xec\\xa0\\x95\\xeb\\xb3\\xb4 \\xea\\xb0\\x80\\xec\\xa0\\xb8\\xec\\x98\\xa4\\xea\\xb8\\xb0(\\xec\\x9b\\xb9 \\xed\\x81\\xac\\xeb\\xa1\\xa4\\xeb\\xa7\\x81) </a> <br>\\n\\t</ul>\\n</body>\\n</html>'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "# 웹 페이지 가져오기\n",
    "url = \"https://ldjwj.github.io/webPage/\"\n",
    "response = requests.get(url)\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01. 제목 가져오기(title) ./01.html\n",
      "02. 텍스트 가져오기(p) ./02.html\n",
      "03. 링크 가져오기(a) ./03.html\n",
      "04. 이미지 정보 가져오기(img) https://ldjwj.github.io/webPage/04.html\n",
      "05. 리스트 정보 가져오기(ul,ol) ./05.html\n",
      "06. id를 활용한 정보 획득 ./06.html\n",
      "07. class를 활용한 정보 획득 ./07.html\n",
      "08. 하나의 이미지 다운로드 ./08.html\n",
      "09. 여러개의 이미지 다운로드 https://pythonstart.github.io/web/09.html\n",
      "10. 랭킹 정보 가져오기(웹 크롤링) ./10.html\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "# 웹 페이지 가져오기\n",
    "url = \"https://ldjwj.github.io/webPage/\"\n",
    "response = requests.get(url)\n",
    "\n",
    "# BeautifulSoup 객체 생성\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# 모든 링크 가져오기\n",
    "links = soup.find_all('a')\n",
    "\n",
    "# 링크 탐색하기\n",
    "for link in links:\n",
    "    # 링크의 텍스트와 URL 출력하기\n",
    "    print(link.text.strip(), link['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<img height=\"214px\" src=\"dog01.jpg\" width=\"322px\"/>,\n",
       " <img height=\"214px\" src=\"dog02.jpg\" width=\"322px\"/>]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "# 웹 페이지 가져오기\n",
    "url = \"https://ldjwj.github.io/webPage/04.html\"\n",
    "res = requests.get(url)\n",
    "# BeautifulSoup 객체 생성\n",
    "soup = BeautifulSoup(res.content, 'html.parser')\n",
    "# 이미지 태그 가져오기\n",
    "img_tags = soup.find_all('img')\n",
    "img_tags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://ldjwj.github.io/webPage/dog01.jpg\n",
      "https://ldjwj.github.io/webPage/dog02.jpg\n"
     ]
    }
   ],
   "source": [
    "for img in img_tags:\n",
    "    img_url = img['src']\n",
    "    img_ori = \"https://ldjwj.github.io/webPage/\" + img_url\n",
    "    print(img_ori)\n",
    "    img_res = requests.get(img_ori)\n",
    "    \n",
    "    # 이미지 저장\n",
    "    with open(img_url.split('/')[-1], 'wb') as f:\n",
    "        f.write(img_res.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
